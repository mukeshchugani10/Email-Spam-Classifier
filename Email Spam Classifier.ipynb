{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Lists to store filenames\n",
    "ham_filenames = []              \n",
    "spam_filenames = []\n",
    "\n",
    "for each in sorted(os.listdir(r'easy_ham')):\n",
    "    if len(each)>20:\n",
    "        ham_filenames.append(each)\n",
    "\n",
    "for each in sorted(os.listdir(r'spam')):\n",
    "    if len(each)>20:\n",
    "        spam_filenames.append(each)\n",
    "        \n",
    "print(len(ham_filenames),len(spam_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 500\n"
     ]
    }
   ],
   "source": [
    "import email\n",
    "import email.parser\n",
    "import email.policy\n",
    "# Lists to store respective e-mails\n",
    "ham_emails = []\n",
    "spam_emails = []\n",
    "\n",
    "for each in ham_filenames:\n",
    "    with open('easy_ham/'+each, \"rb\") as t:\n",
    "        ham_emails.append(email.parser.BytesParser(policy=email.policy.default).parse(t))\n",
    "        \n",
    "for each in spam_filenames:\n",
    "    with open('spam/'+each, \"rb\") as t:\n",
    "        spam_emails.append(email.parser.BytesParser(policy=email.policy.default).parse(t))\n",
    "        \n",
    "print(len(ham_emails),len(spam_emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email.message.EmailMessage"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ham_emails[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an instance of the EmailMessage class.<br>\n",
    "Visit https://docs.python.org/3/library/email.message.html for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Spam and Ham emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
      "    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      "    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "\n",
      "\n",
      "  | I can't reproduce this error.\n",
      "\n",
      "For me it is very repeatable... (like every time, without fail).\n",
      "\n",
      "This is the debug log of the pick happening ...\n",
      "\n",
      "18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
      "18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n",
      "18:19:04 Ftoc_PickMsgs {{1 hit}}\n",
      "18:19:04 Marking 1 hits\n",
      "18:19:04 tkerror: syntax error in expression \"int ...\n",
      "\n",
      "Note, if I run the pick command by hand ...\n",
      "\n",
      "delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n",
      "1 hit\n",
      "\n",
      "That's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\n",
      "using is ...\n",
      "\n",
      "delta$ pick -version\n",
      "pick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n",
      "\n",
      "And the relevant part of my .mh_profile ...\n",
      "\n",
      "delta$ mhparam pick\n",
      "-seq sel -list\n",
      "\n",
      "\n",
      "Since the pick command works, the sequence (actually, both of them, the\n",
      "one that's explicit on the command line, from the search popup, and the\n",
      "one that comes from .mh_profile) do get created.\n",
      "\n",
      "kre\n",
      "\n",
      "ps: this is still using the version of the code form a day ago, I haven't\n",
      "been able to reach the cvs repository today (local routing issue I think).\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "Exmh-workers mailing list\n",
      "Exmh-workers@redhat.com\n",
      "https://listman.redhat.com/mailman/listinfo/exmh-workers\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[0].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A POWERHOUSE GIFTING PROGRAM You Don't Want To Miss! \n",
      " \n",
      "  GET IN WITH THE FOUNDERS! \n",
      "The MAJOR PLAYERS are on This ONE\n",
      "For ONCE be where the PlayerS are\n",
      "This is YOUR Private Invitation\n",
      "\n",
      "EXPERTS ARE CALLING THIS THE FASTEST WAY \n",
      "TO HUGE CASH FLOW EVER CONCEIVED\n",
      "Leverage $1,000 into $50,000 Over and Over Again\n",
      "\n",
      "THE QUESTION HERE IS:\n",
      "YOU EITHER WANT TO BE WEALTHY \n",
      "OR YOU DON'T!!!\n",
      "WHICH ONE ARE YOU?\n",
      "I am tossing you a financial lifeline and for your sake I \n",
      "Hope you GRAB onto it and hold on tight For the Ride of youR life!\n",
      "\n",
      "Testimonials\n",
      "\n",
      "Hear what average people are doing their first few days:\n",
      "�We've received 8,000 in 1 day and we are doing that over and over again!' Q.S. in AL\n",
      " �I'm a single mother in FL and I've received 12,000 in the last 4 days.� D. S. in FL\n",
      "�I was not sure about this when I sent off my $1,000 pledge, but I got back $2,000 the very next day!� L.L. in KY\n",
      "�I didn't have the money, so I found myself a partner to work this with. We have received $4,000 over the last 2 days. \n",
      "I think I made the right decision; don't you?� K. C. in FL\n",
      "�I pick up $3,000 my first day and I  they gave me free leads and all the training, you can too!� J.W. in CA\n",
      "\n",
      "ANNOUNCING: We will CLOSE your sales for YOU! And Help you get a Fax Blast IMMEDIATELY Upon Your Entry!!!    YOU Make the MONEY!!!\n",
      "FREE LEADS!!! TRAINING!!!\n",
      "\n",
      "$$DON'T WAIT!!! CALL NOW $$\n",
      "FAX BACK TO: 1-800-421-6318 OR Call 1-800-896-6568 \n",
      "\n",
      "Name__________________________________Phone___________________________________________\n",
      "\n",
      "Fax_____________________________________Email____________________________________________\n",
      "\n",
      "Best Time To Call_________________________Time Zone________________________________________\n",
      "\n",
      "This message is sent in compliance of the new e-mail bill. \"Per Section 301, Paragraph (a)(2)(C) of S. 1618, further transmissions by the sender of this email may be stopped, at no cost to you, by sending a reply to this email address with the word \"REMOVE\" in the subject line. Errors, omissions, and exceptions excluded.\n",
      " \n",
      "This is NOT spam! I have compiled this list from our Replicate Database, relative to Seattle Marketing Group, The Gigt, or Turbo Team for the sole purpose of these communications. Your continued inclusion is ONLY by your gracious permission. If you wish to not receive this mail from me, please send an email to tesrewinter@yahoo.com with \"Remove\" in the subject and you will be deleted immediately.\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[5].get_content().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various structures of emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A recursive function to list down the type of an email (including its subparts)\n",
    "\n",
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()\n",
    "\n",
    "# A function to get the type of each email and also count them\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham:\n",
      "[('text/plain', 2408), ('multipart(text/plain, application/pgp-signature)', 66), ('multipart(text/plain, text/html)', 8), ('multipart(text/plain, text/plain)', 4), ('multipart(text/plain)', 3), ('multipart(text/plain, application/octet-stream)', 2), ('multipart(text/plain, text/enriched)', 1), ('multipart(text/plain, application/ms-tnef, text/plain)', 1), ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)', 1), ('multipart(text/plain, video/mng)', 1), ('multipart(text/plain, multipart(text/plain))', 1), ('multipart(text/plain, application/x-pkcs7-signature)', 1), ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)', 1), ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))', 1), ('multipart(text/plain, application/x-java-applet)', 1)]\n",
      "Spam:\n",
      "[('text/plain', 218), ('text/html', 183), ('multipart(text/plain, text/html)', 45), ('multipart(text/html)', 20), ('multipart(text/plain)', 19), ('multipart(multipart(text/html))', 5), ('multipart(text/plain, image/jpeg)', 3), ('multipart(text/html, application/octet-stream)', 2), ('multipart(text/plain, application/octet-stream)', 1), ('multipart(text/html, text/plain)', 1), ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1), ('multipart(multipart(text/plain, text/html), image/gif)', 1), ('multipart/alternative', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Most common structures in each category\n",
    "print('Ham:',structures_counter(ham_emails).most_common(),sep='\\n')\n",
    "print('Spam:',structures_counter(spam_emails).most_common(),sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that most of the spam emails have html code in them. Also, most of the ham emails have pgp signatures.\n",
    "<br> -'multipart' refers to multiple subparts within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails+spam_emails)              # Append the second list to the first\n",
    "y = np.array([0]*len(ham_emails) + [1]*len(spam_emails))    # 0 is appended len(ham_emails) times followed by 1's len(spam_emails) times\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Emails to plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "# A function to convert html code to text using regex\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# A function which converts the given email to plain text\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue                              # Ignore the images and other types\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n",
      "<HTML><HEAD>\n",
      "<META content=\"text/html; charset=windows-1252\" http-equiv=Content-Type>\n",
      "<META content=\"MSHTML 5.00.2314.1000\" name=GENERATOR></HEAD>\n",
      "<BODY><!-- Inserted by Calypso -->\n",
      "<TABLE border=0 cellPadding=0 cellSpacing=2 id=_CalyPrintHeader_ rules=none \n",
      "style=\"COLOR: black; DISPLAY: none\" width=\"100%\">\n",
      "  <TBODY>\n",
      "  <TR>\n",
      "    <TD colSpan=3>\n",
      "      <HR color=black noShade SIZE=1>\n",
      "    </TD></TR></TD></TR>\n",
      "  <TR>\n",
      "    <TD colSpan=3>\n",
      "      <HR color=black noShade SIZE=1>\n",
      "    </TD></TR></TBODY></TABLE><!-- End Calypso --><!-- Inserted by Calypso --><FONT \n",
      "color=#000000 face=VERDANA,ARIAL,HELVETICA size=-2><BR></FONT></TD></TR></TABLE><!-- End Calypso --><FONT color=#ff0000 \n",
      "face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Save up to 70% on Life Insurance.</CENTER></FONT><FONT color=#ff0000 \n",
      "face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Why Spend More Than You Have To?\n",
      "<CENTER><FONT color=#ff0000 face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Life Quote Savings\n",
      "<CENTER>\n",
      "<P align=left></P>\n",
      "<P align=left></P></FONT></U></I></B><BR></FONT></U></B></U></I>\n",
      "<P></P>\n",
      "<CENTER>\n",
      "<TABLE border=0 borderColor=#111111 cellPadding=0 cellSpacing=0 width=650>\n",
      "  <TBODY></TBODY></TABLE>\n",
      "<TABLE border=0 borderColor=#111111 cellPadding=5 cellSpacing=0 width=650>\n",
      "  <TBODY>\n",
      "  <TR>\n",
      "    <TD colSpan=2 width=\"35%\"><B><FONT face=Verdana size=4>Ensuring your \n",
      "      family's financial security is very important. Life Quote Savings makes \n",
      "      buying life insurance simple and affordable. We Provide FREE Access to The \n",
      "      Very Best Companies and The Lowest Rates.</FONT></B></TD></TR>\n",
      "  <TR>\n",
      "    <TD align=middle vAlign=top width=\"18%\">\n",
      "      <TABLE borderColor=#111111 width=\"100%\">\n",
      "        <TBODY>\n",
      "        <TR>\n",
      "          <TD style=\"PADDING-LEFT: 5px; PADDING-RIGHT: 5px\" width=\"100%\"><FONT \n",
      "            face=Verdana size=4><B>Life Quote Savings</B> is FAST, EASY and \n",
      "            SAVES you money! Let us help you get started with the best values in \n",
      "            the country on new coverage. You can SAVE hundreds or even thousands \n",
      "            of dollars by requesting a FREE quote from Lifequote Savings. Our \n",
      "            service will take you less than 5 minutes to complete. Shop and \n",
      "            compare. SAVE up to 70% on all types of Life insurance! \n",
      "</FONT></TD></TR>\n",
      "        <TR><BR><BR>\n",
      "          <TD height=50 style=\"PADDING-LEFT: 5px; PADDING-RIGHT: 5px\" \n",
      "          width=\"100%\">\n",
      "            <P align=center><B><FONT face=Verdana size=5><A \n",
      "            href=\"http://website.e365.cc/savequote/\">Click Here For Your \n",
      "            Free Quote!</A></FONT></B></P></TD>\n",
      "          <P><FONT face=Verdana size=4><STRONG>\n",
      "          <CENTER>Protecting your family is the best investment you'll ever \n",
      "          make!<BR></B></TD></TR>\n",
      "        <TR><BR><BR></STRONG></FONT></TD></TR></TD></TR>\n",
      "        <TR></TR></TBODY></TABLE>\n",
      "      <P align=left><FONT face=\"Arial, Helvetica, sans-serif\" size=2></FONT></P>\n",
      "      <P></P>\n",
      "      <CENTER><BR><BR><BR>\n",
      "      <P></P>\n",
      "      <P align=left><BR></B><BR><BR><BR><BR></P>\n",
      "      <P align=center><BR></P>\n",
      "      <P align=left><BR></B><BR><BR></FONT>If you are in receipt of this email \n",
      "      in error and/or wish to be removed from our list, <A \n",
      "      href=\"mailto:coins@btamail.net.cn\">PLEASE CLICK HERE</A> AND TYPE REMOVE. If you \n",
      "      reside in any state which prohibits e-mail solicitations for insurance, \n",
      "      please disregard this \n",
      "      email.<BR></FONT><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR></FONT></P></CENTER></CENTER></TR></TBODY></TABLE></CENTER></CENTER></CENTER></CENTER></CENTER></BODY></HTML>\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[0].get_content().strip())       # Email before conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save up to 70% on Life Insurance.\n",
      "Why Spend More Than You Have To?\n",
      "Life Quote Savings\n",
      "    Ensuring your\n",
      "      family's financial security is very important. Life Quote Savings makes\n",
      "      buying life insurance simple and affordable. We Provide FREE Access to The\n",
      "      Very Best Companies and The Lowest Rates.\n",
      "          Life Quote Savings is FAST, EASY and\n",
      "            SAVES you money! Let us help you get started with the best values in\n",
      "            the country on new coverage. You can SAVE hundreds or even thousands\n",
      "            of dollars by requesting a FREE quote from Lifequote Savings. Our\n",
      "            service will take you less than 5 minutes to complete. Shop and\n",
      "            compare. SAVE up to 70% on all types of Life insurance!\n",
      "             HYPERLINK Click Here For Your\n",
      "            Free Quote!\n",
      "          Protecting your family is the best investment you'll ever\n",
      "          make!\n",
      "      If you are in receipt of this email\n",
      "      in error and/or wish to be removed from our list,  HYPERLINK PLEASE CLICK HERE AND TYPE REMOVE. If you\n",
      "      reside in any state which prohibits e-mail solicitations for insurance,\n",
      "      please disregard this\n",
      "      email.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(spam_emails[0]))              # Email after conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a transformer class which converts an email to a word counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urlextract\n",
    "import nltk\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "url_extractor = urlextract.URLExtract()\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"            # First, convert the email to plain text completely\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:   # Replace any urls with \"URL\"\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:                              # Replace all the numbers with \"NUMBER\"\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:                           # Remove punctuations\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())             # Split the text into words and get the count of each word\n",
    "            if self.stemming and stemmer is not None:       # Get the count of only the stem of each word\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'a': 10, 'i': 7, 'to': 7, 'song': 5, 'the': 4, 'and': 4, 'url': 4, 'of': 3, 'playlist': 3, 'digit': 3, 'is': 3, 'not': 3, 'their': 3, 'm': 3, 'up': 3, 'law': 2, 'can': 2, 'number': 2, 'from': 2, 'inform': 2, 'that': 2, 'if': 2, 'it': 2, 'websit': 2, 'with': 2, 'servic': 2, 'as': 2, 'info': 2, 'my': 2, 'anyon': 1, 'heard': 1, 'thi': 1, 'befor': 1, 'q': 1, 'get': 1, 'we': 1, 'are': 1, 'unabl': 1, 'offer': 1, 'perform': 1, 'right': 1, 'in': 1, 'sound': 1, 'record': 1, 'act': 1, 'pass': 1, 'by': 1, 'congress': 1, 'prevent': 1, 'us': 1, 'disclos': 1, 'such': 1, 'state': 1, 'one': 1, 'transmit': 1, 'signal': 1, 'cannot': 1, 'be': 1, 'pre': 1, 'announc': 1, 'music': 1, 'choic': 1, 'polici': 1, 'releas': 1, 'upcom': 1, 'or': 1, 'previous': 1, 'play': 1, 'recent': 1, 'musicchoic': 1, 'upgrad': 1, 'veri': 1, 'import': 1, 'far': 1, 'concern': 1, 'real': 1, 'time': 1, 'directv': 1, 'receiv': 1, 'on': 1, 'shelf': 1, 'display': 1, 'scroll': 1, 'intermitt': 1, 'sure': 1, 'go': 1, 'fire': 1, 'projector': 1, 'while': 1, 'listen': 1, 'radio': 1, 'so': 1, 'quit': 1, 'happi': 1, 'retriev': 1, 'r': 1, 't': 1, 'like': 1, 'etc': 1, 'now': 1, 'were': 1, 'more': 1, 'eager': 1, 'hacker': 1, 'd': 1, 'write': 1, 'littl': 1, 'wsdl': 1, 'stub': 1, 'for': 1, 'these': 1, 'event': 1, 'stream': 1, 'they': 1, 're': 1, 'clearli': 1, 'worri': 1, 'about': 1, 'load': 1, 'sinc': 1, 'own': 1, 'web': 1, 'page': 1, 'specifi': 1, 'sec': 1, 'meta': 1, 'refresh': 1, 'then': 1, 'feed': 1, 'em': 1, 'through': 1, 'content': 1, 'router': 1, 'alert': 1, 'me': 1, 'cool': 1, 'heck': 1, 'cross': 1, 'refer': 1, 'cddb': 1, 'rk': 1}),\n",
       "       Counter({'i': 8, 'to': 6, 'html': 6, 'a': 6, 'the': 5, 'in': 5, 'd': 4, 'strip': 4, 'that': 4, 'thi': 4, 'get': 4, 'but': 3, 'it': 3, 'on': 3, 'text': 3, 'like': 3, 'tag': 2, 'from': 2, 'time': 2, 'rate': 2, 'my': 2, 'corpora': 2, 'though': 2, 's': 2, 'good': 2, 'corpu': 2, 'than': 2, 'save': 2, 't': 2, 'much': 2, 'so': 2, 'url': 2, 'too': 2, 'prefer': 1, 'everyth': 1, 'last': 1, 'tri': 1, 'still': 1, 'had': 1, 'bad': 1, 'effect': 1, 'error': 1, 'your': 1, 'are': 1, 'bias': 1, 'respect': 1, 'newsgroup': 1, 'have': 1, 'strong': 1, 'social': 1, 'taboo': 1, 'post': 1, 'mani': 1, 'peopl': 1, 'person': 1, 'inbox': 1, 'is': 1, 'quit': 1, 'abund': 1, 'ham': 1, 'may': 1, 'prove': 1, 'be': 1, 'bigger': 1, 'hurdl': 1, 'own': 1, 'mail': 1, 'doesn': 1, 'reflect': 1, 'what': 1, 'receiv': 1, 'sinc': 1, 'and': 1, 'throw': 1, 'away': 1, 'select': 1, 'more': 1, 'past': 1, 'multipart': 1, 'mix': 1, 'plain': 1, 'brief': 1, 'plu': 1, 'long': 1, 'copi': 1, 'websit': 1, 'ah': 1, 'explain': 1, 'whi': 1, 'didn': 1, 'again': 1, 'offer': 1, 'add': 1, 'an': 1, 'option': 1, 'argument': 1, 'token': 1, 'they': 1, 'here': 1, 'if': 1, 'gloss': 1, 'over': 1, 'third': 1, 'would': 1, 'feel': 1, 'loss': 1, 'wink': 1, 'll': 1, 'bite': 1, 'sound': 1, 'idea': 1, 'case': 1, 'see': 1, 'how': 1, 'improv': 1, 'f': 1, 'p': 1, 'guido': 1, 'van': 1, 'rossum': 1, 'home': 1, 'page': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[6:8]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert this output into a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# The fit module finds out the most common occuring words in the given word counts and includes the in the 'vocabulary'\n",
    "# whose size is given by the user.\n",
    "\n",
    "# The transform module creates a sparse matrix indicating the number of occurences of each word in the vocabulary.\n",
    "# The number of words which are present in the email but not in vocabulary are indicated as zeros and this number is \n",
    "# shown as the first entry in each row.\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common_ = most_common\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x16 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 30 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=15)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[154,  10,   7,   7,   4,   1,   2,   4,   0,   1,   1,   5,   2,\n",
       "          4,   1,   2],\n",
       "       [134,   6,   8,   6,   5,   5,   4,   2,   6,   4,   4,   0,   3,\n",
       "          1,   4,   2]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()   # Sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'i': 2,\n",
       " 'to': 3,\n",
       " 'the': 4,\n",
       " 'in': 5,\n",
       " 'that': 6,\n",
       " 'url': 7,\n",
       " 'html': 8,\n",
       " 'thi': 9,\n",
       " 'get': 10,\n",
       " 'song': 11,\n",
       " 'it': 12,\n",
       " 'and': 13,\n",
       " 'd': 14,\n",
       " 'from': 15}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_ # Words selected in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "final_pipeline = Pipeline([('prep_wordcount',EmailToWordCounterTransformer()),\n",
    "                           ('prep_sparse',WordCounterToVectorTransformer())])\n",
    "\n",
    "X_train_transformed = final_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  0,  0, ...,  0,  0,  0],\n",
       "       [41,  0, 11, ...,  0,  0,  0],\n",
       "       [16,  1,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [86, 29, 20, ...,  0,  0,  0],\n",
       "       [12,  6,  2, ...,  0,  0,  0],\n",
       "       [75, 28, 11, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=0.98375, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.985, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................... , score=0.9925, total=   0.2s\n",
      "[0.98375 0.985   0.9925 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "\n",
    "log_cls = LogisticRegression()\n",
    "print(log_cls)\n",
    "score = cross_val_score(log_cls,X_train_transformed,y_train,cv=3,verbose=3)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1989,    6],\n",
       "       [  25,  380]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix\n",
    "\n",
    "y_pred = cross_val_predict(log_cls,X_train_transformed,y_train,cv=3)\n",
    "confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.985   0.98375 0.99125]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier()\n",
    "print(cross_val_score(nn,X_train_transformed,y_train,cv=3,scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9675  0.9725  0.97125]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "print(cross_val_score(rf,X_train_transformed,y_train,cv=3,scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94625 0.9575  0.9725 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_cls = SGDClassifier(random_state=42,max_iter=5)\n",
    "print(cross_val_score(sgd_cls,X_train_transformed,y_train,cv=3,scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Logistic Regression` seems like a good choice for a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] C=0.003 .........................................................\n",
      "[CV] ............................ C=0.003, score=0.9625, total=   0.0s\n",
      "[CV] C=0.003 .........................................................\n",
      "[CV] ............................ C=0.003, score=0.9675, total=   0.0s\n",
      "[CV] C=0.003 .........................................................\n",
      "[CV] ........................... C=0.003, score=0.96625, total=   0.0s\n",
      "[CV] C=0.03 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.03, score=0.97, total=   0.0s\n",
      "[CV] C=0.03 ..........................................................\n",
      "[CV] ............................ C=0.03, score=0.97625, total=   0.0s\n",
      "[CV] C=0.03 ..........................................................\n",
      "[CV] ............................ C=0.03, score=0.98375, total=   0.0s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] ............................. C=0.3, score=0.98125, total=   0.0s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] .............................. C=0.3, score=0.9825, total=   0.1s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] .............................. C=0.3, score=0.9925, total=   0.1s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ............................... C=1, score=0.98375, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.985, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................ C=1, score=0.9925, total=   0.2s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] ............................... C=3, score=0.98375, total=   0.0s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] ............................... C=3, score=0.98625, total=   0.1s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] ................................ C=3, score=0.9925, total=   0.3s\n",
      "[CV] C=30 ............................................................\n",
      "[CV] ................................. C=30, score=0.98, total=   0.1s\n",
      "[CV] C=30 ............................................................\n",
      "[CV] ................................ C=30, score=0.985, total=   0.2s\n",
      "[CV] C=30 ............................................................\n",
      "[CV] ............................... C=30, score=0.9925, total=   0.3s\n",
      "[CV] C=300 ...........................................................\n",
      "[CV] ............................. C=300, score=0.97375, total=   0.2s\n",
      "[CV] C=300 ...........................................................\n",
      "[CV] ............................. C=300, score=0.98125, total=   0.2s\n",
      "[CV] C=300 ...........................................................\n",
      "[CV] ............................. C=300, score=0.99125, total=   0.3s\n",
      "[CV] C=3000 ..........................................................\n",
      "[CV] ............................. C=3000, score=0.9725, total=   0.1s\n",
      "[CV] C=3000 ..........................................................\n",
      "[CV] ............................ C=3000, score=0.98375, total=   0.3s\n",
      "[CV] C=3000 ..........................................................\n",
      "[CV] ............................ C=3000, score=0.99125, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.003, 0.03, 0.3, 1, 3, 30, 300, 3000]}\n",
    "grid_search_log_cls = GridSearchCV(log_cls,param_grid,cv=3,verbose=3,scoring='accuracy',return_train_score=True)\n",
    "grid_search_log_cls.fit(X_train_transformed,y_train)\n",
    "\n",
    "log_cls = grid_search_log_cls.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[500   5]\n",
      " [  2  93]]\n",
      "0.9489795918367347\n",
      "0.9789473684210527\n",
      "0.9637305699481866\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed = final_pipeline.transform(X_test)\n",
    "y_pred = log_cls.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "print(precision_score(y_test,y_pred),recall_score(y_test,y_pred),f1_score(y_test,y_pred),sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the Logistic Regression model produced a precision of `94.8%` and a recall of `97.8%`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
